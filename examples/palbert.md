Пример исследовательской идеи, на основе которой была опубликована [статья](https://arxiv.org/abs/2204.03276) на NeurIPS 2022. Важно отметить, что в пропозале могут быть пропущены какие-то важные детали по введению в область/проблему, но если вы вдруг пишите про что-то, и не уверены насколько мы погружены в эту проблему -- то лучше расписать подробнее.

## PALBERT – Early Exiting Done Right

### TL;DR

Опишите идею в паре предложений.

- Улучшение PonderNet, которое лучше учитывает неопределенность предсказаний модели и дает более точный результат

### Motivation

Опишите проблему, которую хочется решить. Почему это важно?

- Языковые модели становятся больше. Если мы дообучаем их на какой-то downstream задаче, то хочется, чтобы полученная модель могла работать быстро. Можно делать это разными способами. Один из них – ранний выход из вычислений. Более того, есть [интуиция](https://proceedings.neurips.cc/paper/2020/file/d4dd111a4fd973394238aca5c05bebe3-Paper.pdf), что модели с ранним выходом могут работать даже лучше, чем без него.

### Related Work

Что уже есть по этой теме? В первую очередь статьи, потом имплементации и всё остальное. Напишите по 1-2 предложению для каждой из статьи, чтобы было понятно, о чем они, какие результаты они получили и насколько им можно доверять.

- 2020, [PABEE](https://proceedings.neurips.cc/paper/2020/file/d4dd111a4fd973394238aca5c05bebe3-Paper.pdf)
  - Делают головы классификатора между каждым из слоёв Трансформера. Когда N классификаторов дают одно и то же предсказание в ряд – выходят из вычислений. Не совсем понятно, как этот метод применить для, например, QA моделей.
- 2021, [PonderNet](https://arxiv.org/abs/2107.05407)
  - Схема для раннего выхода через нижнюю границу на правдоподобие. В отличии от PABEE, можно применять для произвольных задач
- Много других подходов: [FastBERT](https://aclanthology.org/2020.acl-main.537/), [DeeBERT](https://arxiv.org/abs/2004.12993), [BERxiT](https://aclanthology.org/2021.eacl-main.8/).
  - Как правило, либо что-то в сторону, либо ортогональные накрутки поверх PABEE.

### Idea

Как предлагается решить проблему? Что нового в этом решении? Здесь хочется увидеть достаточно подробное описание.

- PonderNet обучает Лямбда-слои, которые выдают вероятность выхода с каждого слоя. Однако, во время инференса, чтобы решить, стоит ли выходить со слоя, они сэмплируют решение с вероятностью, выданной Лямбда-слоем. Такой подход, очевидно, привносит большую неопределенность в предсказания: даже если Лямбда-слой говорит нам, что выходить нужно с 10% вероятностью на первом слое, в 1 из 10 случаев мы выйдем из модели слишком рано.
- Можно попробовать считать CDF Лямбда-слоев, и выходить из вычислений в тот момент, когда она достигает заданного трешхолда.
- Здесь, помимо более высоких чисел в табличках, можно поставить много интересных экспериментов (например, о том, как разные параметры обучения влияют на распределение слоев выхода).

### Discussion

Почему это будет работать? Может быть, есть работы, из которых можно сделать такой вывод или построить некую интуицию. Bonus: почему это может не заработать? На что стоит обратить внимание.

- В целом, сам PonderNet работает, нижним границам на правдоподобие сто лет в обед.
- Может не заработать потому что считать CDF для Лямбда-слоев мало чем обосновано. Но интуитивно кажется, что сделать так можно.

### Experiments A

Как быстро проверить идею на работоспособность (условно, за пару недель), чтобы решить, стоит ли копать в нее дальше.

#### Какие датасеты придется использовать? Доступны ли они публично?
- [GLUE](https://gluebenchmark.com)/[SuperGLUE](https://super.gluebenchmark.com). Все доступны в Hugging Face

#### Какие есть baselines для предложенного метода? Есть ли они вообще? Доступны ли они публично?
- PABEE, в первую очередь. Остальные методы, которые докручивают ортогональные обвесы вокруг PABEE, кажется что, не сильно интересны. Такие ортогональные обвесы можно докрутить и на PALBERT.
- PonderNet во вторую. Важно показать, что критерий раннего выхода влияет на качество. Здесь сложность, что PonderNet от DeepMind, а поэтому на офф реализацию можно не расчитывать. С другой стороны, метод тривиален для реализации.

#### Какие метрики будут использоваться, чтобы показать, что идея работает? Насколько сложно посчитать эти метрики
- Метрики соответствующих задач из GLUE/SuperGLUE. Все доступны в Hugging Face

#### Как решить спустя пару недель, работает ли идея? Какие для этого есть критерии? Какие критерии того, что идея все-таки не работает?
- Главный критерий: Получается улучшить числа PABEE
- Критерий остановки: Не получается улучшить числа даже относительно оригинального PonderNet

#### Примерная оценка по времени
- На 4-8 GPU можно запустить перебор гиперпараметров для 3-4 датасетов и проверить идеи на них. Если там работает, то посчитаться на оставшихся датасетах. 
- Исходные эксперименты можно будет репортить как ablation study.

### Experiments B

Что делать, если идея все-таки заработает?

- Считаться на всех датасетах с разными бэкбонами (ALBERT, RoBERTa, etc).
- Важное: раз работаем лучше PonderNet, нужно показать, что дело именно в неопределенности предсказаний. Оригинальный критерий выхода с сэмплированием можно видеть как single-sample Monte-Carlo estimation. Для эксперимента можно посчитать честное матожидание предсказаний модели по вероятностям с каждого слоя и сравниться с сэмплированием. Важно посмотреть, как будут соотноситься эти критерии. Для статьи достаточно sampling < CDF <= Expectation.
- Анализ поведения модели. Как зависит качество/скорость от трешхолда CDF и от исходных гиперпараметров обучения.
- Дополнительное: можно попробовать докрутить Лямбда-слои до лучшего качества. Кажется, что один линейный слой, который работает поверх скрытых представлений текущего слоя Трансформера – это не самое умное, что можно придумать. Можно попробовать стакать несколько предыдущих скрытых представлений, чтобы ловить динамику в их изменении.
